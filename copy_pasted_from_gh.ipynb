{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba00c916-912f-45b0-834d-fddcd878a05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmas: красивый энди красиво мыть рама\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'красивый',\n",
       "    'wt': 1,\n",
       "    'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'}],\n",
       "  'text': 'красивый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'энди',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,имя,муж,од=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}],\n",
       "  'text': 'энди'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'красиво', 'wt': 0.8149252476, 'gr': 'ADV='}],\n",
       "  'text': 'красиво'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'мыть', 'wt': 1, 'gr': 'V,несов,пе=инф'}],\n",
       "  'text': 'мыть'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'рама', 'wt': 0.9942164394, 'gr': 'S,жен,неод=им,ед'}],\n",
       "  'text': 'рама'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "text = \"Красивая Энди красиво мыла раму\"\n",
    "m = Mystem()\n",
    "lemmas = m.lemmatize(text)\n",
    "\n",
    "print(\"lemmas:\", ''.join(lemmas))\n",
    "arr = m.analyze(''.join(lemmas))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e3fd1b3-8777-4d70-93fb-ec91ac1a8cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import string\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "\n",
    "class SpamToxicDetector:\n",
    "    def __init__(self, model, tokenizer, word2vec, idx2label):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.idx2label = idx2label\n",
    "        self.word2vec = word2vec\n",
    "        self.mean = np.mean(word2vec.vectors, axis=0)\n",
    "        self.std = np.std(word2vec.vectors, axis=0)\n",
    "\n",
    "    def get_tokens(self, text):\n",
    "        return [token for token in self.tokenizer.tokenize(text.lower()) if token not in russian_stopwords and\n",
    "                all(symbol not in string.punctuation for symbol in token) and len(token) >= 3]\n",
    "\n",
    "    def get_avg_embedding(self, tokens):\n",
    "        embedding = [(self.word2vec[token] - self.mean) / self.std for token in tokens if token in self.word2vec]\n",
    "\n",
    "        if len(embedding) == 0:\n",
    "            embedding = np.zeros(self.word2vec.vector_size)\n",
    "        else:\n",
    "            embedding = np.mean(embedding, axis=0)\n",
    "        return embedding\n",
    "\n",
    "    def make_prediction(self, text):\n",
    "        tokens = self.get_tokens(text)\n",
    "        embedding = self.get_avg_embedding(tokens)\n",
    "        pred = self.model(torch.tensor(embedding).float())\n",
    "        pred_label_idx = torch.argmax(pred).item()\n",
    "        return self.idx2label[pred_label_idx]\n",
    "\n",
    "\n",
    "def load_w2v():\n",
    "    word2vec = api.load(\"word2vec-ruscorpora-300\")\n",
    "    return word2vec\n",
    "\n",
    "\n",
    "def load_tokenizer():\n",
    "    return WordPunctTokenizer()\n",
    "\n",
    "\n",
    "def load_model(path, embed_size, num_classes):\n",
    "    model = nn.Sequential(\n",
    "                      nn.Linear(embed_size, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 16),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(16, num_classes)\n",
    "    )\n",
    "    model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1efca7a-a86f-4e64-8107-f608962011ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2label = {0: 'bad', 1: 'good', 2: 'neutral'}\n",
    "num_classes = len(idx2label)\n",
    "word2vec = load_w2v()\n",
    "tokenizer = load_tokenizer()\n",
    "model = load_model('./model.pt', word2vec.vector_size, num_classes)\n",
    "\n",
    "classifier = SpamToxicDetector(model, tokenizer, word2vec, idx2label)\n",
    "text = 'я люблю этот фильм но в конце концовку слили в целом'\n",
    "classifier.make_prediction(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ec2cf-bae4-4306-9fe3-eee6038059dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
