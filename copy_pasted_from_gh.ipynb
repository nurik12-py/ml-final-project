{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba00c916-912f-45b0-834d-fddcd878a05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmas: красивый энди красиво мыть рама\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'красивый',\n",
       "    'wt': 1,\n",
       "    'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'}],\n",
       "  'text': 'красивый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'энди',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,имя,муж,од=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}],\n",
       "  'text': 'энди'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'красиво', 'wt': 0.8149252476, 'gr': 'ADV='}],\n",
       "  'text': 'красиво'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'мыть', 'wt': 1, 'gr': 'V,несов,пе=инф'}],\n",
       "  'text': 'мыть'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'рама', 'wt': 0.9942164394, 'gr': 'S,жен,неод=им,ед'}],\n",
       "  'text': 'рама'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "text = \"Красивая Энди красиво мыла раму\"\n",
    "m = Mystem()\n",
    "lemmas = m.lemmatize(text)\n",
    "\n",
    "print(\"lemmas:\", ''.join(lemmas))\n",
    "arr = m.analyze(''.join(lemmas))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e3fd1b3-8777-4d70-93fb-ec91ac1a8cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import string\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "\n",
    "class SpamToxicDetector:\n",
    "    def __init__(self, model, tokenizer, word2vec, idx2label):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.idx2label = idx2label\n",
    "        self.word2vec = word2vec\n",
    "        self.mean = np.mean(word2vec.vectors, axis=0)\n",
    "        self.std = np.std(word2vec.vectors, axis=0)\n",
    "\n",
    "    def get_tokens(self, text):\n",
    "        return [token for token in self.tokenizer.tokenize(text.lower()) if token not in russian_stopwords and\n",
    "                all(symbol not in string.punctuation for symbol in token) and len(token) >= 3]\n",
    "\n",
    "    def get_avg_embedding(self, tokens):\n",
    "        embedding = [(self.word2vec[token] - self.mean) / self.std for token in tokens if token in self.word2vec]\n",
    "\n",
    "        if len(embedding) == 0:\n",
    "            embedding = np.zeros(self.word2vec.vector_size)\n",
    "        else:\n",
    "            embedding = np.mean(embedding, axis=0)\n",
    "        return embedding\n",
    "\n",
    "    def make_prediction(self, text):\n",
    "        tokens = self.get_tokens(text)\n",
    "        embedding = self.get_avg_embedding(tokens)\n",
    "        pred = self.model(torch.tensor(embedding).float())\n",
    "        pred_label_idx = torch.argmax(pred).item()\n",
    "        return self.idx2label[pred_label_idx]\n",
    "\n",
    "\n",
    "def load_w2v():\n",
    "    word2vec = api.load(\"word2vec-ruscorpora-300\")\n",
    "    return word2vec\n",
    "\n",
    "\n",
    "def load_tokenizer():\n",
    "    return WordPunctTokenizer()\n",
    "\n",
    "\n",
    "def load_model(path, embed_size, num_classes):\n",
    "    model = nn.Sequential(\n",
    "                      nn.Linear(300, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.1),\n",
    "                      nn.Linear(64, 3),\n",
    "                      nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "    model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1efca7a-a86f-4e64-8107-f608962011ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 0.weight: copying a param with shape torch.Size([64, 34473]) from checkpoint, the shape in current model is torch.Size([64, 300]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c3102d949288>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mword2vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_w2v\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model.pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpamToxicDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx2label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-05830f5dfa07>\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(path, embed_size, num_classes)\u001b[0m\n\u001b[0;32m     57\u001b[0m                       \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogSoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     )\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\77714\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1482\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m   1483\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m   1484\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 0.weight: copying a param with shape torch.Size([64, 34473]) from checkpoint, the shape in current model is torch.Size([64, 300])."
     ]
    }
   ],
   "source": [
    "idx2label = {0: 'bad', 1: 'good', 2: 'neutral'}\n",
    "num_classes = len(idx2label)\n",
    "word2vec = load_w2v()\n",
    "tokenizer = load_tokenizer()\n",
    "model = load_model('./model.pt', word2vec.vector_size, num_classes)\n",
    "\n",
    "classifier = SpamToxicDetector(model, tokenizer, word2vec, idx2label)\n",
    "text = 'я люблю этот фильм но в конце концовку слили в целом'\n",
    "classifier.make_prediction(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ec2cf-bae4-4306-9fe3-eee6038059dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
