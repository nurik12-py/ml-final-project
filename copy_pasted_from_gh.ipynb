{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e3fd1b3-8777-4d70-93fb-ec91ac1a8cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import string\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "\n",
    "class MyClassifier:\n",
    "    def __init__(self, model, tokenizer, word2vec, idx2label):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.idx2label = idx2label\n",
    "        self.word2vec = word2vec\n",
    "        self.mean = np.mean(word2vec.vectors, axis=0)\n",
    "        self.std = np.std(word2vec.vectors, axis=0)\n",
    "\n",
    "    def get_tokens(self, text):\n",
    "        return [token for token in self.tokenizer.tokenize(text.lower()) if token not in russian_stopwords and\n",
    "                all(symbol not in string.punctuation for symbol in token) and len(token) >= 3]\n",
    "\n",
    "    def get_avg_embedding(self, tokens):\n",
    "        embedding = [(self.word2vec[token] - self.mean) / self.std for token in tokens if token in self.word2vec]\n",
    "\n",
    "        if len(embedding) == 0:\n",
    "            embedding = np.zeros(self.word2vec.vector_size)\n",
    "        else:\n",
    "            embedding = np.mean(embedding, axis=0)\n",
    "        return embedding\n",
    "\n",
    "    def make_prediction(self, text):\n",
    "        tokens = self.get_tokens(text)\n",
    "        embedding = self.get_avg_embedding(tokens)\n",
    "        pred = self.model(torch.tensor(embedding).float())\n",
    "        pred_label_idx = torch.argmax(pred).item()\n",
    "        return self.idx2label[pred_label_idx]\n",
    "\n",
    "\n",
    "def load_w2v():\n",
    "    word2vec = api.load(\"word2vec-ruscorpora-300\")\n",
    "    return word2vec\n",
    "\n",
    "\n",
    "def load_tokenizer():\n",
    "    return WordPunctTokenizer()\n",
    "\n",
    "\n",
    "def load_model(path, embed_size, num_classes):\n",
    "    model = nn.Sequential(\n",
    "                      nn.Linear(embed_size, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 16),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(16, num_classes)\n",
    "    )\n",
    "    model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1efca7a-a86f-4e64-8107-f608962011ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2label = {0: 'bad', 1: 'good', 2: 'neutral'}\n",
    "num_classes = len(idx2label)\n",
    "word2vec = load_w2v()\n",
    "tokenizer = load_tokenizer()\n",
    "model = load_model('./model.pt', word2vec.vector_size, num_classes)\n",
    "\n",
    "classifier = MyClassifier(model, tokenizer, word2vec, idx2label)\n",
    "\n",
    "text = 'я люблю этот фильм но в конце концовку слили в целом'\n",
    "classifier.make_prediction(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb6ec2cf-bae4-4306-9fe3-eee6038059dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вариант с SVM, без нейронки\n",
    "import pickle\n",
    "\n",
    "global svmIrisModel\n",
    "\n",
    "svmIrisFile = open('SVMModel.pckl', 'rb')\n",
    "svmIrisModel = pickle.load(svmIrisFile)\n",
    "svmIrisFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cfac13-3343-4a52-bdac-864488330844",
   "metadata": {},
   "source": [
    "https://blog.socratesk.com/blog/2018/01/29/expose-ML-model-as-REST-API - ссылка на туториал с flask и svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "369eb0fa-45ab-4fb8-abfb-58c6fe18c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove digits, punctuation and other symbols with regex\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "#Create lemmatizer and stopwords list\n",
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer(\"russian\") \n",
    "#Preprocess function\n",
    "def preprocess_text(text):\n",
    "    text = (lambda f: re.sub(r'\\d|\\W', ' ', text))(text)\n",
    "    #tokens = mystem.lemmatize(text.lower())\n",
    "    #tokens = text.lower().split(' ')\n",
    "    tokens = [stemmer.stem(word) for word in text.lower().split(' ')]\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation\\\n",
    "              and len(token) > 3]\n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4762958-18d3-45e5-aee2-52de44aa3112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_prediced = svmIrisModel.predict([text])\n",
    "class_prediced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc0dc9-a2ce-4512-a081-9ac7b7eae4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
